<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Jaehyeok Bae</title>

    <meta name="author" content="Jaehyeok Bae">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Jaehyeok Bae is a Ph.D. student at Stanford University working on AI for Medical Imaging.">
    
    <link rel="shortcut icon" href="assets/images/light_bulb/light_bulb-64x64.png" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
  </head>

  <script async src="https://www.googletagmanager.com/gtag/js?id=G-GLEJQZX72F"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-GLEJQZX72F');
  </script>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Jaehyeok Bae
                </p>
                <p>
                  Hello! I am a second-year Ph.D. student in the <a href="https://ee.stanford.edu/" target="_blank">Department of Electrical Engineering</a> at <a href="https://www.stanford.edu/" target="_blank">Stanford University</a>, 
                  where I am advised by Prof. <a href="https://profiles.stanford.edu/kawin-setsompop" target="_blank">Kawin Setsompop</a> and Prof. <a href="https://profiles.stanford.edu/john-pauly" target="_blank">John M. Pauly</a>.
                </p>
                <p>
                  I received my Bachelor of Science (Summa Cum Laude) in Electrical and Computer Engineering at <a href="https://en.snu.ac.kr/index.html" target="_blank">Seoul National University</a>.
                  Currently, my Ph.D. study is supported by the <a href="https://educationusa.state.gov/scholarships/study-abroad-doctoral-program-ilju-academy-and-culture-foundation" target="_blank">ILJU Academy & Culture Foundation</a>. 
                  Previously, I was supported by the <a href="https://www.kosaf.go.kr/eng/jsp/aid/aid02_01_01.jsp" target="_blank">Presidential Science Scholarship</a> during my undergraduate studies.
                </p>
                
                <p style="text-align:center">
                  <a href="mailto:jhbae110@stanford.edu">Email</a> &nbsp;/&nbsp;
                  <a href="assets/data/CV/Jaehyeok_Bae_CV.pdf" target="_blank">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=VYd28w4AAAAJ" target="_blank">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/jaehyeok-bae-57b866218" target="_blank">LinkedIn</a> &nbsp;/&nbsp;
                  <a href="https://github.com/wogur110" target="_blank">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="assets/data/profile/profile_original.jpg" target="_blank"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="Jaehyeok Bae profile photo" src="assets/data/profile/profile_circle.png" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p style="margin-bottom: 0;">
                  My research interests lie at the intersection of <b>machine learning</b>, <b>computer vision</b>, and <b>biomedical imaging</b>.
                </p>
                <p style="margin-top: 0;">
                  Specifically, I focus on <b>optimizing data acquisition and image reconstruction</b> using <b>deep learning-based accelerated MRI techniques</b>. 
                  My goal is to develop next-generation medical imaging methods that significantly contribute to patient diagnosis and care.
                </p>
                <p>       
                  * denotes equal contribution.
                </p>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="assets/images/06_quicksamp/quicksamp_320.png" alt="QuickSamp Teaser" width="160" height="160">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://archive.ismrm.org/2025/1367.html" target="_blank">
                  <span class="papertitle">QuickSamp: Towards simple, real-time-optimized Sampling Patterns for 3D Accelerated MRI</span>
                </a>  
                <br>
                <strong>Jaehyeok Bae</strong>,
                <a href="https://scholar.google.com/citations?hl=en&user=IpQzwWIAAAAJ" target="_blank">Cagan Alkan</a>,
                <a href="https://scholar.google.com/citations?hl=en&user=n9mOA2IAAAAJ" target="_blank">Shreyas Vasanawala</a>,
                <a href="https://scholar.google.com/citations?hl=en&user=Fc6GIIQAAAAJ" target="_blank">John M. Pauly</a>,
                <a href="https://scholar.google.com/citations?hl=en&user=bYDAyV4AAAAJ" target="_blank">Kawin Setsompop</a>
                <br>
                International Society for Magnetic Resonance in Medicine (<strong>ISMRM</strong>), 2025 <strong>(MAGNA CUM LAUDE)</strong>
                <br>
                <a href="https://drive.google.com/file/d/1EQy3WMqub1dQiBN6MyubxA1bR4Zp2lfA/view?usp=drive_link" target="_blank">abstract</a>
                /
                <a href="https://drive.google.com/file/d/1y24kWiYPd6gD6vEEKtZvfU80Wyl1uTNG/view?usp=drive_link" target="_blank">presentation</a>
                <p></p>
                <p>- Our method simplifies the complexity and drastically improve the speed of sampling pattern generation using only a few parameters. This eliminates extensive retraining, offering a practical alternative for optimizing MRI acquisition across different configurations and use cases.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="assets/images/07_nstm/nstm_320.png" alt="NSTM Teaser" width="160" height="160">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://link.springer.com/chapter/10.1007/978-3-032-06103-4_12" target="_blank">
                  <span class="papertitle">Neural Space-Time Modeling for Motion-Corrected MR Reconstruction</span>
                </a>  
                <br>
                <a href="https://profiles.stanford.edu/aizada-nurdinova" target="_blank">Aizada Nurdinova</a>,
                <a href="https://scholar.google.com/citations?hl=en&user=to2zNj4AAAAJ" target="_blank">Wenqi Huang</a>,
                <a href="https://scholar.google.com/citations?hl=en&user=wL4ptVkAAAAJ" target="_blank">Daniel Raz Abraham</a>,
                <strong>Jaehyeok Bae</strong>,
                <a href="https://profiles.stanford.edu/yimeng-lin" target="_blank">Yimeng Lin</a>,
                <a href="https://scholar.google.com/citations?hl=en&user=bYDAyV4AAAAJ" target="_blank">Kawin Setsompop</a>,
                <a href="https://scholar.google.com/citations?hl=en&user=aBxHVEQAAAAJ" target="_blank">Brian Andrew Hargreaves</a>
                <br>
                International Workshop on Reconstruction and Imaging Motion Estimation at Medical Image Computing and Computer Assisted Intervention (<strong>MICCAI RIME</strong>), 2025
                <br>
                <a href="https://drive.google.com/file/d/1IPIKXB8L2kKoKulEprEatWYIRMk4F0l2/view?usp=drive_link" target="_blank">paper</a>
                /
                <a href="https://rime-miccai25.github.io/index.html" target="_blank">workshop</a>
                <p></p>
                <p>- NSTM introduces an unsupervised, navigator-free framework using Implicit Neural Representations to jointly learn and disentangle motion from image content without pre-training, enabling robust dynamic MRI reconstruction for complex free-breathing acquisitions directly from undersampled k-space data.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="assets/images/03_adapsel/adapsel_320.png" alt="Adaptive Selection Teaser" width="160" height="160">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://smhongok.github.io/ada-sel.html" target="_blank">
                  <span class="papertitle">Adaptive Selection of Sampling-Reconstruction in Fourier Compressed Sensing</span>
                </a>  
                <br>
                <a href="https://smhongok.github.io/" target="_blank">Seongmin Hong</a>,
                <strong>Jaehyeok Bae</strong>,
                <a href="https://list.snu.ac.kr/jongho-lee" target="_blank">Jongho Lee</a>,
                <a href="https://icl.snu.ac.kr/pi" target="_blank">Se Young Chun</a>
                <br>
                European Conference on Computer Vision (<strong>ECCV</strong>), 2024
                <br>
                <a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/08236.pdf" target="_blank">paper</a>
                /
                <a href="https://arxiv.org/abs/2409.11738" target="_blank">arXiv</a>
                /
                <a href="https://smhongok.github.io/ada-sel.html" target="_blank">project</a>
                /
                <a href="https://github.com/smhongok/ada-sel" target="_blank">github</a>
                <p></p>
                <p>- Proposed a novel adaptive selection of sampling-reconstruction framework that selects the best sampling mask and reconstruction network for each input data in Fourier Compressed Sensing.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="assets/images/04_pni/pni_320.png" alt="PNI Anomaly Detection Teaser" width="160" height="160">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://openaccess.thecvf.com/content/ICCV2023/html/Bae_PNI__Industrial_Anomaly_Detection_using_Position_and_Neighborhood_Information_ICCV_2023_paper.html" target="_blank">
                  <span class="papertitle">PNI : Industrial anomaly detection using position and neighborhood information</span>
                </a>  
                <br>
                <strong>Jaehyeok Bae*</strong>,
                <a href="https://scholar.google.com/citations?user=WuQaZMAAAAAJ" target="_blank">Jaehan Lee*</a>,
                <a href="https://scholar.google.com/citations?user=QqFLZQIAAAAJ" target="_blank">Seyun Kim</a>
                <br>
                International Conference on Computer Vision (<strong>ICCV</strong>), 2023
                <br>
                <a href="https://openaccess.thecvf.com/content/ICCV2023/html/Bae_PNI__Industrial_Anomaly_Detection_using_Position_and_Neighborhood_Information_ICCV_2023_paper.html" target="_blank">paper</a>
                /
                <a href="https://drive.google.com/file/d/1gAKqNGhNr72A-16541fAw_A3jDkiB2oI/view?usp=drive_link" target="_blank">video</a>
                /                
                <a href="https://drive.google.com/file/d/1nyMVOhn7wFfPfBISoD5zziJUmIHGPdyY/view?usp=drive_link" target="_blank">poster</a>
                /
                <a href="https://github.com/wogur110/PNI_anomaly_detection" target="_blank">github</a>
                <p></p>
                <p>- Proposed a novel anomaly detection and localization alogrithm for industrial datasets, by training a normal feature distribution using position and neighborhood information of local features.</p>
              </td>
            </tr>
            
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="assets/images/02_nimagenet/nimagenet_320.png" alt="N-ImageNet Teaser" width="160" height="160">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://openaccess.thecvf.com/content/ICCV2021/html/Kim_N-ImageNet_Towards_Robust_Fine-Grained_Object_Recognition_With_Event_Cameras_ICCV_2021_paper.html" target="_blank">
                  <span class="papertitle">N-ImageNet: Towards robust, fine-grained object recognition with event cameras</span>
                </a>  
                <br>
                <a href="https://scholar.google.com/citations?user=u1Sz3YMAAAAJ" target="_blank">Junho Kim</a>,
                <strong>Jaehyeok Bae</strong>,
                <a href="https://www.linkedin.com/in/gangin-park-4b83911a4/" target="_blank">Gangin Park</a>, 
                <a href="https://scholar.google.com/citations?user=ydEYx7QAAAAJ" target="_blank">Dongsu Zhang</a>, 
                <a href="https://scholar.google.com/citations?user=TjYQs-AAAAAJ" target="_blank">Youngmin Kim</a>
                <br>
                International Conference on Computer Vision (<strong>ICCV</strong>), 2021
                <br>
                <a href="https://openaccess.thecvf.com/content/ICCV2021/html/Kim_N-ImageNet_Towards_Robust_Fine-Grained_Object_Recognition_With_Event_Cameras_ICCV_2021_paper.html" target="_blank">paper</a>
                /
                <a href="https://youtu.be/7mWPYGRfk-I" target="_blank">video</a>
                /                
                <a href="https://github.com/82magnolia/n_imagenet" target="_blank">github</a>
                <p></p>
                <p style="margin-bottom: 0;">- Introduced N-ImageNet, a large-scale dataset targeted for robust, fine-grained object recognition with event cameras.</p>
                <p style="margin-top: 0;">- Empirically showed that pretraining on N-ImageNet improves the performance of event-based classifiers.</p>
              </td>
            </tr>

            <!-- <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="assets/images/01_panel/panel_320.png" alt="Perforated Panel Teaser" width="160" height="160">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://drive.google.com/file/d/1McwHJ97gzXrbOloAyvkWUCvPFBOLk8zD/view?usp=drive_link" target="_blank">
                  <span class="papertitle">Design of a perforated panel for transmission noise reduction</span>
                </a>
                <br>
                <a href="https://scholar.google.com/citations?user=eEYGjdMAAAAJ" target="_blank">Younghyo Park</a>, 
                <strong>Jaehyeok Bae</strong>,
                <a href="https://scholar.google.co.kr/citations?user=uP2bXL0AAAAJ" target="_blank">Jin Woo Lee</a>
                <br>
                <em>KSME</em>, A, Vol. 39, No. 4, 2015
                <br>
                <a href="https://drive.google.com/file/d/1McwHJ97gzXrbOloAyvkWUCvPFBOLk8zD/view?usp=drive_link" target="_blank">paper (<em>in Korean</em>)</a>
                <p></p>
                <p>- Proposed a design method for a perforated panel to reduce the level of incident noise without obstructing the flow of incoming fluid. (<em>written in Korean</em>)</p>
              </td>
            </tr> -->
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <h2>Project</h2>
            </td>
            </tr>
          </tbody></table>
          
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <a href="assets/images/05_fastmri/fastmri.png" target="_blank"><img src="assets/images/05_fastmri/fastmri_320.png" alt="FastMRI Challenge Teaser" width="160" height="160" class="hoverZoomLink"></a>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://fastmri.snu.ac.kr/" target="_blank">
                  <span class="papertitle">SNU FastMRI Challenge</span>
                </a>  
                <br>
                <strong>Jaehyeok Bae</strong>,
                <a href="https://www.linkedin.com/in/skkim0428/" target="_blank">Sungkyung Kim</a>
                <br>
                <em>Electrical and Computer Engineering, Seoul National University</em>, 2022~2023
                <br>
                <a href="https://fastmri.snu.ac.kr/" target="_blank">homepage</a>
                /
                <a href="https://drive.google.com/file/d/1VXQu_P9zLPz2fmoryc2ZVyRncr1eoQdY/view?usp=drive_link" target="_blank">ppt</a>
                /
                <a href="https://youtu.be/figDLtEMdaM" target="_blank">video (<em>in Korean</em>)</a>
                /                
                <a href="https://github.com/LISTatSNU/FastMRI_challenge" target="_blank">github</a>
                <p></p>
                <p style="margin-bottom: 0;">- Proposed an algorithm to restore aliased images from accelerated MRI scans into aliasing-free images, 2nd place award in the 2022 competiton.</p>
                <p style="margin-top: 0;">- Served as the contest coordinator for the 2023 competition, evaluating and analyzing the participants' models.</p>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Check out Jon Barron's <a href="https://github.com/jonbarron/jonbarron_website" target="_blank">repository</a> for the template of this website.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>